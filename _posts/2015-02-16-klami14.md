---
title: Polya-gamma augmentations for factor models
abstract: Bayesian inference for latent factor models, such as principal component
  and canonical correlation analysis, is easy for Gaussian likelihoods. In particular,
  full conjugacy makes both Gibbs samplers and mean-field variational approximations
  straightforward. For other likelihood potentials one needs to either resort to more
  complex sampling schemes or to specifying dedicated forms of variational lower bounds.
  Recently, however, it was shown that for specific likelihoods related to the logistic
  function it is possible to augment the joint density with auxiliary variables following
  a Polya-Gamma distribution, leading to closed-form updates for binary and over-dispersed
  count models. In this paper we describe how Gibbs sampling and mean-field variational
  approximation for various latent factor models can be implemented for these cases,
  presenting easy-to-implement and efficient inference schemas.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: klami14
month: 0
tex_title: "{P}olya-gamma augmentations for factor models"
firstpage: 112
lastpage: 128
page: 112-128
sections: 
author:
- given: Arto
  family: Klami
date: 2015-02-16
address: Nha Trang City, Vietnam
publisher: PMLR
container-title: Proceedings of the Sixth Asian Conference on Machine Learning
volume: '39'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 16
pdf: http://proceedings.mlr.press/v39/klami14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
